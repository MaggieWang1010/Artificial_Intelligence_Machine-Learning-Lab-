# -*- coding: utf-8 -*-
"""Lab13 TensorFlow.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/18Yo59CnTRiDndYWY47A9HPK8B2jeuT5B
"""

#---------------------------One /Two dimensional Tensor------------
import numpy as np
tensor_1d = np.array([1.3, 1, 4.0, 23.99]) 
print(tensor_1d)

tensor_2d=np.array([(1,2,3,4),(4,5,6,7),(8,9,10,11),(12,13,14,15)])
print(tensor_2d)

#-----------Tensor Handling and Manipulations-------------
import tensorflow as tf 
print(tf. version )

hello = tf.constant('Hello') 
world = tf.constant(' World') 
type(hello)

print(hello)

with tf.compat.v1.Session() as sess:
  result = sess.run(hello+world)

print(result)

a = tf.constant(10) 
b = tf.constant(20) 
type(a)

a + b 
a + b
with tf.compat.v1.Session() as sess:
  result = sess.run(a+b) 
result
const = tf.constant(10) 
fill_mat = tf.fill((4,4),10) 
myzeros = tf.zeros((4,4)) 
myones = tf.ones((4,4))
myrandn = tf.random.normal((4,4), mean=0, stddev=1.0) 
myrandu = tf.random.uniform((4,4), minval=0, maxval=1) 
myzeros

my_ops=[const, fill_mat, myzeros, myones, myrandn, myrandu] 
sess = tf.compat.v1.InteractiveSession()
for op in my_ops: 
  print(sess.run(op)) 
  print('\n')

a = tf.constant([[1,2], [3,4]]) 
a.get_shape()

b = tf.constant([[10], [100]]) 
b.get_shape()

result = tf.matmul(a,b)
sess.run(result) 
result.eval()

#-----------------Linear regression in TensorFlow--------------------------
import numpy as np 
import tensorflow as tf

import matplotlib.pyplot as plt

np.random.seed(101) 
tf.random.set_seed(101)

# Genrating random linear data
# There will be 50 data points ranging from 0 to 50 
x = np.linspace(0, 50, 50)
y = np.linspace(0, 50, 50)

# Adding noise to the random linear data 
x += np.random.uniform(-4, 4, 50)
y += np.random.uniform(-4, 4, 50) 
n = len(x) # Number of data points
# Plot of Training Data 
plt.scatter(x, y) 
plt.xlabel('x')
plt.xlabel('y') 
plt.title("Training Data") 
plt.show()

import tensorflow.compat.v1 as tf

tf.disable_v2_behavior()  
X = tf.placeholder("float") 
Y = tf.placeholder("float")

W = tf.Variable(np.random.randn(), name = "W") 
b = tf.Variable(np.random.randn(), name = "b")

learning_rate = 0.01
training_epochs = 1000 
# Hypothesis

y_pred = tf.add(tf.multiply(X, W), b)

# Mean Squared Error Cost Function
cost = tf.reduce_sum(tf.pow(y_pred-Y, 2)) / (2 * n)

# Gradient Descent Optimizer
optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)

# Global Variables Initializer
init = tf.global_variables_initializer() 
with tf.Session() as sess:
  # Initializing the Variables 
  sess.run(init)

  # Iterating through all the epochs
  for epoch in range(training_epochs):

    # Feeding each data point into the optimizer using Feed Dictionary 
    for (_x, _y) in zip(x, y):
      sess.run(optimizer, feed_dict = {X : _x, Y : _y})

    # Displaying the result after every 50 epochs 
    if (epoch + 1) % 50 == 0:
      # Calculating the cost a every epoch
      c = sess.run(cost, feed_dict = {X : x, Y : y})
      print("Epoch", (epoch + 1), ": cost =", c, "W =", sess.run(W), "b =", sess.run(b))

  # Storing necessary values to be used outside the Session 
  training_cost = sess.run(cost, feed_dict ={X: x, Y: y}) 
  weight = sess.run(W)
  bias = sess.run(b)

# Calculating the predictions

predictions = weight * x + bias
print("Training cost =", training_cost, "Weight =", weight, "bias =", bias, '\n')

# Plotting the Results
plt.plot(x, y, 'ro', label ='Original data') 
plt.plot(x, predictions, label ='Fitted line') 
plt.title('Linear Regression Result') 
plt.legend()
plt.show()



